{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de dígitos en Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#import mnist\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#train_images = mnist.train_images()\n",
    "\n",
    "#train_labels = mnist.train_labels()\n",
    "\n",
    "#test_images = mnist.test_images()\n",
    "#test_labels = mnist.test_labels()\n",
    "\n",
    "print(train_images.shape) # (60000, 28, 28)\n",
    "print(train_labels.shape) # (60000,)\n",
    "\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir el modelo\n",
    "\n",
    "\n",
    "`model = Sequential([  #layers...])`\n",
    "\n",
    "El constructor de Sequential recibe como parámetro un arreglo de [Layers](https://keras.io/layers/about-keras-layers/) de Keras\n",
    "\n",
    "Para el caso de una red neuronal feed forward solo se requiere de la capa [Dense](https://keras.io/layers/core/#dense), que representa una capa completamente conectada.\n",
    "\n",
    "En este ejemplo añadiremos tres capas al modelo, las primeras dos con 64 nodos cada unoa con la función de activación [relu](https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7) y la última con 10 nodos y función de activación [softmax](https://victorzhou.com/blog/softmax/).\n",
    "\n",
    "Keras requiere conocer la forma de los datos de entrada por medio del parámetro `input_shape` especificado en la primera capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 03:07:15.029295: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-22 03:07:15.041485: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-22 03:07:15.147006: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilar el modelo\n",
    "Es necesario configurar el proceso de entrenamiento considerando tres factores:\n",
    "- El *optimizador*.\n",
    "- La *función de pérdida (loss function)*.\n",
    "- Las *métricas* de optimización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el modelo\n",
    "Para entrenar el modelo se invoca la función `fit` con una serie de [parámetros](https://keras.io/models/sequential/#fit), entre los que destacan:\n",
    "- *Datos de entrenamiento*, incluyendo datos y etiquetas.\n",
    "- *Número de épocas (epochs)*, que representa el número de iteraciones sobre el dataset completo.\n",
    "- *El tamaño del batch* número de muestras por actualización de gradiente.\n",
    "\n",
    "Para este caso Keras espera los targets de entrenamiento como un vector de 10 dimensiones, dado que hay 10 nodos en la capa de salida Softmax, sin embargo train_labels provee de un solo entero que representa la clase de cada imagen. Es por ello que se hace uso del método [to_categorical](https://keras.io/utils/#to_categorical) que convierte al arreglo de enteros en un arreglo de vectores one-hot., por ejemplo 2 estaría representado como `[0,0,1,0,0,0,0,0,0,0,0]` (indexado en cero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 03:07:22.318827: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-03-22 03:07:22.438109: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2593905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5936 - accuracy: 0.8224\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2009 - accuracy: 0.9404\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1446 - accuracy: 0.9548\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1230 - accuracy: 0.9618\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1030 - accuracy: 0.9687\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0905 - accuracy: 0.9709\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0824 - accuracy: 0.9740\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0757 - accuracy: 0.9759\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0695 - accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0621 - accuracy: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17e796c5b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_images, # training data\n",
    "  to_categorical(train_labels), # training targets\n",
    "  epochs=10,\n",
    "  batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probar el modelo\n",
    "Keras provee el método [evaluate](https://keras.io/models/sequential/#evaluate) que regresa un arreglo con la pérdida en prueba (test loss) seguida de las métricas especificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1153 - accuracy: 0.9662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11529228836297989, 0.9661999940872192]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar el modelo\n",
    "El modelo puede guardarse y recuperarse de disco por medio de las funciones `save_weights` y `load_weights`\n",
    "\n",
    "La función `predict` de un modelo permite predecir con datos de prueba o instancias nuevas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 3 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:100])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
