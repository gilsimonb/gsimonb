{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "![McCulloch Pitts](images/mcculloch_pitts.JPG)\n",
    "En 1943 McCulloch y Pitts propusieron el primer modelo matemático de una neurona.\n",
    "\n",
    "Desde una perspectiva de alto nivel, las redes neuronales son codificadores o decodificadores o una combinación de ambos. Los codificadores encuentran patrones en los datos para formar una representación compacta y útil. Los decodificadores generar nuevos datos o información de alta resolución útil a partir de esas representaciones. Desde una perspectiva, Deep Learning descubre formas de representar el mundo para que sea posible razonar de él. \n",
    "\n",
    "Desde la perspectiva de sistemas, las redes neuronales artificiales son un sistema de software que modelan la anatomía y capacidad de procesamiento de información de las neuronas y sinapsis biológicas. \n",
    "\n",
    "![Biological neuron](images/biological-neuron.png)\n",
    "\n",
    "**Dendrita**: recibe señales de otras neuronas.\n",
    "\n",
    "**Soma**: Procesa la información.\n",
    "\n",
    "**Axón**: Transmite la salida de la neurona.\n",
    "\n",
    "**Sinapsis**: Punto de conexión con otras neuronas.\n",
    "\n",
    "Una neurona toma una señal de entrada (dendrita), la procesa como un CPU (soma), pasa la salida por medio de una estructra similar a un cable a otras neuronas conectadas (axón a sinapisis a las dendritas de otras neuronas).\n",
    "\n",
    "\n",
    "\n",
    "El primer modelo computacional de una neurona fue propuesto por Warren McCulloch y Walter Pitts (1943). El modelo está dividido en dos partes. En la primera $g$ toma una entrada (dendrida), lleva a cabo una agregación y de acuerdo en el valor agregado la segunda parte $f$ toma una decisión. \n",
    "![McCulloch-Pitts Neuron](images/mcculloch-pitts-neuron.png)\n",
    "\n",
    "\n",
    "Las entradas pueden ser excitatorias o inhibitorias. Las entradas inhibitorias son aquellas que tienen un máximo efecto en la toma de decisiones, independientemente de otras entradas en cuyo caso la salida será 0. Las entradas excitatorias no ocasionan que la neurona dispare sola, sin embargo puede la disparar con una combinación de entradas excitatorias.\n",
    "\n",
    "![Formal neural network](images/formal-nn.png)\n",
    "\n",
    "$g(x)$ está haciendo una suma de entradas, una simple agregación. $_theta$ representa a un umbral que controla la salida de la neurona. \n",
    "\n",
    "![Neuron model](images/neuron-model.jpg)\n",
    "Relación de la arquitectura biológica de la neurona con el modelo matemático. \n",
    "\n",
    "## Función de activación\n",
    "La salida de una neurona se calcula al aplicar una transformación $f$ sobre una suma ponderada de las señales de entrada. Esta transformación $f$ se conoce como la función de activación que generalmente se selecciona como no lineal. Esto permite que la red neuronal aprenda transformaciones no lineales complejas sobre la señal de entrada.\n",
    "\n",
    "Algunos ejemplos de funciones de activación:\n",
    "- Función de identidad $f(x) = x$\n",
    "- Función logística $f(x)=(1+e~(-x))^{-1}$\n",
    "- Sigmoidal $\\sigma(x)=1/(1+e^{-x})$\n",
    "- Tangencial $tanh(x)$\n",
    "- ReLU: rectified linear unit $y=max(0, ..., x)$\n",
    "\n",
    "## Función de pérdida (loss function)\n",
    "- La función de pérdida cuantifica la diferencia entre la predicción y el valor real.\n",
    "- Para el caso de regresión usualmente se emplea Mean Squared Error.\n",
    "$MSE = (1/N)\\sum(t_i-s_i)^{2}$\n",
    "- Para el caso de clasificación usualmente se emplea Cross Entropy Loss $CE = -\\sum(t_i*log(s_i))$\n",
    "\n",
    "## Backpropagation\n",
    "Tiene como propósito actualizar los pesos y el bias para decrementar la función de pérdida.\n",
    "![Forward propagation](images/forward-propagation.jpg)\n",
    "![Backpropagation](images/backpropagation.jpg)\n",
    "### Proceso backpropagation\n",
    "1. Forward pass para calcular la salida de la red y el error.\n",
    "2. Back propagation para calcular los gradientes.\n",
    "3. Una fracción del gradiente del peso se substrae del peso.\n",
    "\n",
    "## Tipos de redes neuronales\n",
    "1. Feed Forward Neural Networks. Se trata de redes neuronales artificiales en donde las conexiones entre los nodos no forman ciclos. Se emplean para clasificación y regresión basada en características.\n",
    "2. Convolutional Neural Networks. Redes neuronales profundas que generalmente se aplican en procesamiento de imágenes con aplicaciones en reconocimiento de imágenes y video, sistemas de recomendaciones, clasificación de imágenes y procesamiento de lenguaje natural. Se hace uso de la operación lineal conocida como convolución en vez de una multiplicación general de matrices en al menos una de sus capas.\n",
    "3. Recurrent Neural Networks. También conocidas como redes auto asociativas o de retroalimentación, son redes neuronales en donde  las conexiones entre sus unidades forman un ciclo directo. Se emplean en modelado de lenguaje, reconocimiento y generación de lenguaje.\n",
    "4. Encoder Decoder Architecture. Arquitectura para redes neuronales de tipo recurrente que actualmente representan el método estándar para traducción neuronal automatizada. \n",
    "5. Autoencoder. Redes neuronales que aprenden codificaciones eficientes de datos de forma no supervisada. Empleados en  reconocimiento facial y determinación del significado de palabras. Se emplean para reducción de dimensiones y para entrenar las redes a ignorar ruido.\n",
    "6. Generative Adversarial Networks. Redes neuronales que compiten entre sí. La red productora crea candidatos, mientras que la red discriminatoria los evalua. El objetivo de la red productora es incrementar la tasa de error de la red discriminatoria. Empleadas para crear fotografías muy realistas de sujetos, incluyendo personas, paisajes y portadas de discos.\n",
    "7. Deep Reinforcement Learning. Emplea los principios de deep learning y reinforcement learning para crear algoritmos eficientes que se apliquen en robótica, video juegos, finanzas y salud. Se aplica en juegos, simulaciones de robótica.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}