{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "## Introducción\n",
    "Keras es un API de alto nivel para redes neuronales, escrita en Python que es capaz de correr sobre TensorFlow, CNTK o Theano. Fue desarrollada con énfasis en habilitar experimentación rápida. Es recomendable el uso de Keras cuando se requiere de una libería de Deep Learning que:\n",
    "- Permita el desarrollo de prototipos fácil y rápido (por medio de facilidad de uso, modularidad y extensibilidad).\n",
    "- Soporte redes neuronales convolucionales (CNN) y redes neuronales recurrentes (RNN), así como combinaciones de ambas.\n",
    "- Corra de forma natural en CPUs y GPUs.\n",
    "\n",
    "Keras es compatible con Python 2.7-3.6.\n",
    "\n",
    "[keras.io](https://keras.io) es el sitio principal del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backend Keras y tf.keras\n",
    "Se recomienda usar `tf.keras` a usuarios que usen Keras multi-backend con TensorFlow en TensorFlow 2.0 ya que `tf.keras` tiene mejor integración con las características de TensorFlow 2.0 (eager execution, soporte a distribución)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principios\n",
    "- **Amigable**. El API está diseñado para personas, es consistente, reduce el número de pasos para casos de uso comunes. \n",
    "- **Modular**. Un modelo de deep learning consta de una secuencia o un grafo de módulos configurables que pueden ser conectados  con la menor cantidad de restricciones. Las capas de las redes neuronales, las funciones de costo, los optimizadores, esqueasm de inicialización, funciones de activación y esquemas de regularización son módulos independientes que pueden combinarse para crear nuevos modelos.\n",
    "- **Extensible**. Es posible añadir módulos nuevos\n",
    "- **Trabaja con Python**. No requiere de archivos de configuración de modelos. Los modelos se describen en Python, que es compacto, fácil de depurar y facilita la extensibilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructuras de datos\n",
    "La estructura central de Keras es un modelo, que representa una forma de organizar capas. `Sequential` representa al modelo más simple, una pila linear de capas. El **Functional API**, por medio de `Model` permite crear arquitecturas más complejas por medio de un grafo arbitrario de capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "#from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preprocesamiento de datos\n",
    "Las redes neuronales no procesan datos crudos como archivos de texto, imágenes codificadas en JPEG y otros formatos, o archivos CSV. Procesan representaciones vectorizadas y estandarizadas.\n",
    "* Los archivos de texto necesitan ser leidos a tensores de sequencias de caracteres, divididos en palabrsa. Las palabras necesitan ser indexadas y convertidas a tensores de enteros.\n",
    "* Las imágenes necesitan ser leídas y decodificadas en tensores de imágenes, convertidas a punto flotante y normalizados a valores pequeños (generalmente entre 0 y 1).\n",
    "* Los datos CSV necesitan ser leídos, con características numéricas convertidas a tensores de punto flotante y características categóricas indexadas y convertidas a tensores enteros. Cada característica necesita ser normalizada con media cero y variación unitaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3670\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 02:06:29.514353: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-22 02:06:29.531405: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-22 02:06:29.534601: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-03-22 02:06:30.083236: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-03-22 02:06:30.084742: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2593905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(32, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(32,)\n",
      "<dtype: 'int32'>\n",
      "(22, 180, 180, 3)\n",
      "<dtype: 'float32'>\n",
      "(22,)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "#Obtener un dataset etiquetado de imágenes en disco\n",
    "# Create a dataset.\n",
    "image_dataset = k.preprocessing.image_dataset_from_directory(\n",
    "  data_dir, batch_size=32, image_size=(180, 180))\n",
    "\n",
    "# For demonstration, iterate over the batches yielded by the dataset.\n",
    "for data, labels in image_dataset:\n",
    "   print(data.shape)  # (64, 200, 200, 3)\n",
    "   print(data.dtype)  # float32\n",
    "   print(labels.shape)  # (64,)\n",
    "   print(labels.dtype)  # int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./datasets’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  17.9M      0  0:00:04  0:00:04 --:--:-- 17.9M\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./datasets\n",
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz --directory ./datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 files belonging to 3 classes.\n",
      "b'This is the kind of film that, if it were made today, it would probably star Sandra Bullock and Hugh Grant; actually, now that I think about it, this one is quite liable to be remade one day. It\\'s pleasant, but with no depth whatsoever. It suffers from the almost fatal miscasting of James Stewart in a role he is about 20 years too old for, and as a result there is no chemistry between him and the beautiful Kim Novak. Ernie Kovacs, in the small supporting role of an aspiring writer, is the only actor in the film whose performance approaches what you might call \"wit\". (**1/2)'\n",
      "1\n",
      "b\"I've seen hundreds of films at the theater and this was one of only two during which I actually fell asleep. Steve Martin and Bill Murray, along with the Dentist song, try to salvage an otherwise slow uninteresting film. In my book, this is one where the original was more enjoyable.\"\n",
      "2\n",
      "b'Fairly interesting exploitation flick in black and white written by David F. Friedman. The lead actress Stacey Walker is well-cast and strangely attractive. She resembles a deranged Renee Zellweger with a bad hair-do. This chick only made two of these films and then moved back to Texas. The music is terrible. One of her boyfriends is played by Sam Melville (from the TV show THE ROOKIES) using a different name.<br /><br />Best line in the film from Tony - \"Are you putting me on, doll? None of my chicks put me on\". Good B/W cinematography from Laslo Kovacs (EASY RIDER & TARGETS & many others). Good locales (cool swimming pool, also used in THE DEFILERS). Strange ending but fitting. A 4 out of 10. Best performance Stacey Walker.'\n",
      "0\n",
      "b\"Ouch! They don't come much worse than this horrid adaptation of C. S. Lewis's beloved novel. While the adaptation is very true to the novel, the acting is simply awful and the sets and special effects are on a scale equivalent to a school play. I've read that the budget for this miniseries was the grandest that the BBC has ever given at the time, but surely they could have scraped together a bit more than the $2 that it looks like this was filmed for. The worst effect of all is Mr. Beaver. I know computer effects weren't at the level necessary or even cost effective at the time, but the costume store man in a suit look was horrid. Better to have just cut the character from the film than do that to the role! Avoid this at all costs.\"\n",
      "0\n",
      "b\"It's Die Hard meets Cliffhanger when a ski resort is besieged by terrorists and it's up to one cop, Jack (Crackerjack) to stop this.<br /><br />A B-action movie that borrows from other films and is quite good with pretty good action, a ridiculous plot (as always in these movies) and three fine stars. Thomas Ian Griffith as the cop and Nastasja Kinski and Christopher Plummer as terrorists. If you don't like stupid B-action movies this is not for you.\"\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Obtener un dataset etiquetado de archivos de texto en disco\n",
    "text_dataset = k.preprocessing.text_dataset_from_directory(\n",
    "  './datasets/aclImdb/train', batch_size=64)\n",
    "\n",
    "# For demonstration, iterate over the batches yielded by the dataset.\n",
    "for text_batch, label_batch in text_dataset.take(1):\n",
    "    for i in range(5):\n",
    "        print(text_batch.numpy()[i])\n",
    "        print(label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos en Keras\n",
    "* Generar tokens de secuencias de caracteres, posteriormente índices de tokens.\n",
    "* Normalizar características.\n",
    "* Reescalar los datos a valores pequeños (media cero y variación unitaria o datos en el rango [0, 1]).\n",
    "\n",
    "Keras permite realizar el preprocesamiento de datos como parte del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 5 2 9 3]\n",
      " [7 6 2 8 3]], shape=(2, 5), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "# Example training data, of dtype `string`.\n",
    "training_data = np.array([[\"This is the 1st sample.\"], [\"And here's the 2nd sample.\"]])\n",
    "\n",
    "# Create a TextVectorization layer instance. It can be configured to either\n",
    "# return integer token indices, or a dense token representation (e.g. multi-hot\n",
    "# or TF-IDF). The text standardization and text splitting algorithms are fully\n",
    "# configurable.\n",
    "vectorizer = TextVectorization(output_mode=\"int\")\n",
    "\n",
    "# Calling `adapt` on an array or dataset makes the layer generate a vocabulary\n",
    "# index for the data, which can then be reused when seeing new data.\n",
    "vectorizer.adapt(training_data)\n",
    "\n",
    "# After calling adapt, the layer is able to encode any n-gram it has seen before\n",
    "# in the `adapt()` data. Unknown n-grams are encoded via an \"out-of-vocabulary\"\n",
    "# token.\n",
    "integer_data = vectorizer(training_data)\n",
    "print(integer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]], shape=(2, 17), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Convertir secuencias de caracteres a bigrams de tipo one-hot encoding\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "# Example training data, of dtype `string`.\n",
    "training_data = np.array([[\"This is the 1st sample.\"], [\"And here's the 2nd sample.\"]])\n",
    "\n",
    "# Create a TextVectorization layer instance. It can be configured to either\n",
    "# return integer token indices, or a dense token representation (e.g. multi-hot\n",
    "# or TF-IDF). The text standardization and text splitting algorithms are fully\n",
    "# configurable.\n",
    "vectorizer = TextVectorization(output_mode=\"binary\", ngrams=2)\n",
    "\n",
    "# Calling `adapt` on an array or dataset makes the layer generate a vocabulary\n",
    "# index for the data, which can then be reused when seeing new data.\n",
    "vectorizer.adapt(training_data)\n",
    "\n",
    "# After calling adapt, the layer is able to encode any n-gram it has seen before\n",
    "# in the `adapt()` data. Unknown n-grams are encoded via an \"out-of-vocabulary\"\n",
    "# token.\n",
    "integer_data = vectorizer(training_data)\n",
    "print(integer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 1.0000\n",
      "mean: -0.0000\n"
     ]
    }
   ],
   "source": [
    "# Normalización de características\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "\n",
    "# Example image data, with values in the [0, 255] range\n",
    "training_data = np.random.randint(0, 256, size=(64, 200, 200, 3)).astype(\"float32\")\n",
    "\n",
    "normalizer = Normalization(axis=-1)\n",
    "normalizer.adapt(training_data)\n",
    "\n",
    "normalized_data = normalizer(training_data)\n",
    "print(\"var: %.4f\" % np.var(normalized_data))\n",
    "print(\"mean: %.4f\" % np.mean(normalized_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (64, 150, 150, 3)\n",
      "min: 0.0\n",
      "max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Cambiar la escala, centrar y recortar imágenes\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "# Example image data, with values in the [0, 255] range\n",
    "training_data = np.random.randint(0, 256, size=(64, 200, 200, 3)).astype(\"float32\")\n",
    "\n",
    "cropper = CenterCrop(height=150, width=150)\n",
    "scaler = Rescaling(scale=1.0 / 255)\n",
    "\n",
    "output_data = scaler(cropper(training_data))\n",
    "print(\"shape:\", output_data.shape)\n",
    "print(\"min:\", np.min(output_data))\n",
    "print(\"max:\", np.max(output_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de instancia de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto se haya definido el grafo de capas que convierte las entradas en salidas, es posible instanciar el objeto Model().\n",
    "```\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "```\n",
    "Es posible invocar el modelo en subconjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = k.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6851/1400466393.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "data = np.random.randint(0, 256, size=(64, 200, 200, 3)).astype(\"float32\")\n",
    "processed_data = model(data)\n",
    "print(processed_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible desplegar un resumen de las trasnformaciones de datos en cada etapa. Esto es útil para depuración.\n",
    "```\n",
    "model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos con fit()\n",
    "Hasta este punto:\n",
    "* Los datos se encuentran preparados.\n",
    "* Se ha definido un modelo para ajustar los datos.\n",
    "El siguiente paso es entrenar el modelo con los datos. La clase Model cuenta con un ciclo de entrenamiento, el método fit().\n",
    "\n",
    "Antes de invocar fit() se debe especificar un optimizador y una función de pérdida. Este es el paso compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6851/2369803298.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n\u001b[0m\u001b[1;32m      2\u001b[0m               loss=keras.losses.CategoricalCrossentropy())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "              loss=keras.losses.CategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de pérdida y el optimizador puede ser especificada por medio de sus identificadores como cadenas de caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando el modelo está compilado, es posible comenzar a ajustar el modelo a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(numpy_array_of_samples, numpy_array_of_labels,\n",
    "          batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "También es posible especificar el tamaño del batch y el número de épocas (iteraciones sobre los datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset_of_samples_and_labels, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
