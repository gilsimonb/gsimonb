{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Clasificación binaria\n",
    "Se implementará un modelo de clasificación binaria para un datasets con clases altamente desbalanceadas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Vectorizar los datos CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
    "fname = \"/dl-data/creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "source": [
    "## Preparar un dataset de validación"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training samples: 227846\nNumber of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "source": [
    "## Analizar el desbalance de clases en los targets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "source": [
    "## Normalizar los datos empleando estadísticas del training set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "source": [
    "## Generar un modelo de clasificación binaria"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 256)               7936      \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndropout (Dropout)            (None, 256)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 139,777\nTrainable params: 139,777\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "## Entrenar el modelo con el argumento class_weight"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "112/112 - 9s - loss: 2.3809e-06 - fn: 50.0000 - fp: 28361.0000 - tn: 199068.0000 - tp: 367.0000 - precision: 0.0128 - recall: 0.8801 - val_loss: 0.1184 - val_fn: 9.0000 - val_fp: 836.0000 - val_tn: 56050.0000 - val_tp: 66.0000 - val_precision: 0.0732 - val_recall: 0.8800\n",
      "Epoch 2/30\n",
      "112/112 - 3s - loss: 1.4114e-06 - fn: 32.0000 - fp: 6478.0000 - tn: 220951.0000 - tp: 385.0000 - precision: 0.0561 - recall: 0.9233 - val_loss: 0.1242 - val_fn: 7.0000 - val_fp: 1705.0000 - val_tn: 55181.0000 - val_tp: 68.0000 - val_precision: 0.0384 - val_recall: 0.9067\n",
      "Epoch 3/30\n",
      "112/112 - 3s - loss: 1.2458e-06 - fn: 28.0000 - fp: 8495.0000 - tn: 218934.0000 - tp: 389.0000 - precision: 0.0438 - recall: 0.9329 - val_loss: 0.1154 - val_fn: 6.0000 - val_fp: 2315.0000 - val_tn: 54571.0000 - val_tp: 69.0000 - val_precision: 0.0289 - val_recall: 0.9200\n",
      "Epoch 4/30\n",
      "112/112 - 4s - loss: 9.4162e-07 - fn: 23.0000 - fp: 5939.0000 - tn: 221490.0000 - tp: 394.0000 - precision: 0.0622 - recall: 0.9448 - val_loss: 0.0413 - val_fn: 10.0000 - val_fp: 645.0000 - val_tn: 56241.0000 - val_tp: 65.0000 - val_precision: 0.0915 - val_recall: 0.8667\n",
      "Epoch 5/30\n",
      "112/112 - 4s - loss: 8.9427e-07 - fn: 23.0000 - fp: 6927.0000 - tn: 220502.0000 - tp: 394.0000 - precision: 0.0538 - recall: 0.9448 - val_loss: 0.0428 - val_fn: 7.0000 - val_fp: 580.0000 - val_tn: 56306.0000 - val_tp: 68.0000 - val_precision: 0.1049 - val_recall: 0.9067\n",
      "Epoch 6/30\n",
      "112/112 - 4s - loss: 7.9801e-07 - fn: 16.0000 - fp: 6873.0000 - tn: 220556.0000 - tp: 401.0000 - precision: 0.0551 - recall: 0.9616 - val_loss: 0.0207 - val_fn: 11.0000 - val_fp: 214.0000 - val_tn: 56672.0000 - val_tp: 64.0000 - val_precision: 0.2302 - val_recall: 0.8533\n",
      "Epoch 7/30\n",
      "112/112 - 4s - loss: 2.1711e-06 - fn: 27.0000 - fp: 9343.0000 - tn: 218086.0000 - tp: 390.0000 - precision: 0.0401 - recall: 0.9353 - val_loss: 0.0710 - val_fn: 10.0000 - val_fp: 435.0000 - val_tn: 56451.0000 - val_tp: 65.0000 - val_precision: 0.1300 - val_recall: 0.8667\n",
      "Epoch 8/30\n",
      "112/112 - 4s - loss: 1.2733e-06 - fn: 27.0000 - fp: 6514.0000 - tn: 220915.0000 - tp: 390.0000 - precision: 0.0565 - recall: 0.9353 - val_loss: 0.0411 - val_fn: 10.0000 - val_fp: 452.0000 - val_tn: 56434.0000 - val_tp: 65.0000 - val_precision: 0.1257 - val_recall: 0.8667\n",
      "Epoch 9/30\n",
      "112/112 - 4s - loss: 1.1265e-06 - fn: 22.0000 - fp: 6104.0000 - tn: 221325.0000 - tp: 395.0000 - precision: 0.0608 - recall: 0.9472 - val_loss: 0.0871 - val_fn: 7.0000 - val_fp: 1373.0000 - val_tn: 55513.0000 - val_tp: 68.0000 - val_precision: 0.0472 - val_recall: 0.9067\n",
      "Epoch 10/30\n",
      "112/112 - 5s - loss: 9.8925e-07 - fn: 14.0000 - fp: 5825.0000 - tn: 221604.0000 - tp: 403.0000 - precision: 0.0647 - recall: 0.9664 - val_loss: 0.0352 - val_fn: 9.0000 - val_fp: 470.0000 - val_tn: 56416.0000 - val_tp: 66.0000 - val_precision: 0.1231 - val_recall: 0.8800\n",
      "Epoch 11/30\n",
      "112/112 - 4s - loss: 7.8692e-07 - fn: 13.0000 - fp: 5228.0000 - tn: 222201.0000 - tp: 404.0000 - precision: 0.0717 - recall: 0.9688 - val_loss: 0.0564 - val_fn: 8.0000 - val_fp: 965.0000 - val_tn: 55921.0000 - val_tp: 67.0000 - val_precision: 0.0649 - val_recall: 0.8933\n",
      "Epoch 12/30\n",
      "112/112 - 5s - loss: 1.4422e-06 - fn: 11.0000 - fp: 7121.0000 - tn: 220308.0000 - tp: 406.0000 - precision: 0.0539 - recall: 0.9736 - val_loss: 0.0437 - val_fn: 9.0000 - val_fp: 1044.0000 - val_tn: 55842.0000 - val_tp: 66.0000 - val_precision: 0.0595 - val_recall: 0.8800\n",
      "Epoch 13/30\n",
      "112/112 - 4s - loss: 1.0669e-06 - fn: 15.0000 - fp: 7652.0000 - tn: 219777.0000 - tp: 402.0000 - precision: 0.0499 - recall: 0.9640 - val_loss: 0.0379 - val_fn: 8.0000 - val_fp: 580.0000 - val_tn: 56306.0000 - val_tp: 67.0000 - val_precision: 0.1036 - val_recall: 0.8933\n",
      "Epoch 14/30\n",
      "112/112 - 4s - loss: 8.4149e-07 - fn: 10.0000 - fp: 7252.0000 - tn: 220177.0000 - tp: 407.0000 - precision: 0.0531 - recall: 0.9760 - val_loss: 0.0336 - val_fn: 10.0000 - val_fp: 406.0000 - val_tn: 56480.0000 - val_tp: 65.0000 - val_precision: 0.1380 - val_recall: 0.8667\n",
      "Epoch 15/30\n",
      "112/112 - 6s - loss: 7.5308e-07 - fn: 13.0000 - fp: 4757.0000 - tn: 222672.0000 - tp: 404.0000 - precision: 0.0783 - recall: 0.9688 - val_loss: 0.0806 - val_fn: 8.0000 - val_fp: 1794.0000 - val_tn: 55092.0000 - val_tp: 67.0000 - val_precision: 0.0360 - val_recall: 0.8933\n",
      "Epoch 16/30\n",
      "112/112 - 4s - loss: 5.5253e-07 - fn: 4.0000 - fp: 5402.0000 - tn: 222027.0000 - tp: 413.0000 - precision: 0.0710 - recall: 0.9904 - val_loss: 0.0747 - val_fn: 10.0000 - val_fp: 1258.0000 - val_tn: 55628.0000 - val_tp: 65.0000 - val_precision: 0.0491 - val_recall: 0.8667\n",
      "Epoch 17/30\n",
      "112/112 - 5s - loss: 4.3666e-07 - fn: 4.0000 - fp: 4263.0000 - tn: 223166.0000 - tp: 413.0000 - precision: 0.0883 - recall: 0.9904 - val_loss: 0.0300 - val_fn: 10.0000 - val_fp: 632.0000 - val_tn: 56254.0000 - val_tp: 65.0000 - val_precision: 0.0933 - val_recall: 0.8667\n",
      "Epoch 18/30\n",
      "112/112 - 4s - loss: 3.9666e-07 - fn: 4.0000 - fp: 4742.0000 - tn: 222687.0000 - tp: 413.0000 - precision: 0.0801 - recall: 0.9904 - val_loss: 0.0183 - val_fn: 9.0000 - val_fp: 389.0000 - val_tn: 56497.0000 - val_tp: 66.0000 - val_precision: 0.1451 - val_recall: 0.8800\n",
      "Epoch 19/30\n",
      "112/112 - 5s - loss: 4.6795e-07 - fn: 3.0000 - fp: 5997.0000 - tn: 221432.0000 - tp: 414.0000 - precision: 0.0646 - recall: 0.9928 - val_loss: 0.0224 - val_fn: 9.0000 - val_fp: 531.0000 - val_tn: 56355.0000 - val_tp: 66.0000 - val_precision: 0.1106 - val_recall: 0.8800\n",
      "Epoch 20/30\n",
      "112/112 - 5s - loss: 2.8791e-07 - fn: 3.0000 - fp: 3457.0000 - tn: 223972.0000 - tp: 414.0000 - precision: 0.1069 - recall: 0.9928 - val_loss: 0.0459 - val_fn: 9.0000 - val_fp: 952.0000 - val_tn: 55934.0000 - val_tp: 66.0000 - val_precision: 0.0648 - val_recall: 0.8800\n",
      "Epoch 21/30\n",
      "112/112 - 4s - loss: 5.4389e-07 - fn: 7.0000 - fp: 6286.0000 - tn: 221143.0000 - tp: 410.0000 - precision: 0.0612 - recall: 0.9832 - val_loss: 0.0345 - val_fn: 9.0000 - val_fp: 649.0000 - val_tn: 56237.0000 - val_tp: 66.0000 - val_precision: 0.0923 - val_recall: 0.8800\n",
      "Epoch 22/30\n",
      "112/112 - 5s - loss: 3.1284e-07 - fn: 2.0000 - fp: 3875.0000 - tn: 223554.0000 - tp: 415.0000 - precision: 0.0967 - recall: 0.9952 - val_loss: 0.0352 - val_fn: 9.0000 - val_fp: 890.0000 - val_tn: 55996.0000 - val_tp: 66.0000 - val_precision: 0.0690 - val_recall: 0.8800\n",
      "Epoch 23/30\n",
      "112/112 - 5s - loss: 2.4924e-07 - fn: 2.0000 - fp: 3368.0000 - tn: 224061.0000 - tp: 415.0000 - precision: 0.1097 - recall: 0.9952 - val_loss: 0.0148 - val_fn: 9.0000 - val_fp: 272.0000 - val_tn: 56614.0000 - val_tp: 66.0000 - val_precision: 0.1953 - val_recall: 0.8800\n",
      "Epoch 24/30\n",
      "112/112 - 5s - loss: 2.7062e-07 - fn: 3.0000 - fp: 3076.0000 - tn: 224353.0000 - tp: 414.0000 - precision: 0.1186 - recall: 0.9928 - val_loss: 0.1563 - val_fn: 6.0000 - val_fp: 2950.0000 - val_tn: 53936.0000 - val_tp: 69.0000 - val_precision: 0.0229 - val_recall: 0.9200\n",
      "Epoch 25/30\n",
      "112/112 - 5s - loss: 2.8145e-07 - fn: 0.0000e+00 - fp: 4412.0000 - tn: 223017.0000 - tp: 417.0000 - precision: 0.0864 - recall: 1.0000 - val_loss: 0.0145 - val_fn: 9.0000 - val_fp: 276.0000 - val_tn: 56610.0000 - val_tp: 66.0000 - val_precision: 0.1930 - val_recall: 0.8800\n",
      "Epoch 26/30\n",
      "112/112 - 5s - loss: 3.0146e-07 - fn: 4.0000 - fp: 3268.0000 - tn: 224161.0000 - tp: 413.0000 - precision: 0.1122 - recall: 0.9904 - val_loss: 0.0820 - val_fn: 8.0000 - val_fp: 2515.0000 - val_tn: 54371.0000 - val_tp: 67.0000 - val_precision: 0.0259 - val_recall: 0.8933\n",
      "Epoch 27/30\n",
      "112/112 - 5s - loss: 3.3064e-07 - fn: 3.0000 - fp: 4227.0000 - tn: 223202.0000 - tp: 414.0000 - precision: 0.0892 - recall: 0.9928 - val_loss: 0.0398 - val_fn: 9.0000 - val_fp: 811.0000 - val_tn: 56075.0000 - val_tp: 66.0000 - val_precision: 0.0753 - val_recall: 0.8800\n",
      "Epoch 28/30\n",
      "112/112 - 4s - loss: 3.1973e-07 - fn: 2.0000 - fp: 3794.0000 - tn: 223635.0000 - tp: 415.0000 - precision: 0.0986 - recall: 0.9952 - val_loss: 0.0172 - val_fn: 11.0000 - val_fp: 343.0000 - val_tn: 56543.0000 - val_tp: 64.0000 - val_precision: 0.1572 - val_recall: 0.8533\n",
      "Epoch 29/30\n",
      "112/112 - 5s - loss: 1.9341e-07 - fn: 1.0000 - fp: 2732.0000 - tn: 224697.0000 - tp: 416.0000 - precision: 0.1321 - recall: 0.9976 - val_loss: 0.0113 - val_fn: 11.0000 - val_fp: 191.0000 - val_tn: 56695.0000 - val_tp: 64.0000 - val_precision: 0.2510 - val_recall: 0.8533\n",
      "Epoch 30/30\n",
      "112/112 - 4s - loss: 4.6675e-07 - fn: 3.0000 - fp: 5700.0000 - tn: 221729.0000 - tp: 414.0000 - precision: 0.0677 - recall: 0.9928 - val_loss: 0.0148 - val_fn: 10.0000 - val_fp: 286.0000 - val_tn: 56600.0000 - val_tp: 65.0000 - val_precision: 0.1852 - val_recall: 0.8667\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f07285b4940>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "source": [
    "## Conclusiones\n",
    "* Número de transacciones de validación.\n",
    "* Número de casos identificados correctamente como fraudulentos.\n",
    "* Número de transacciones fraudulentas faltantes.\n",
    "* Costo de etiquetar 441 transacciones legítimas.\n",
    "Recomendaciones: Colocar un peso mayor en la clase 1 para reflejar que los falsos negativos son más costosos que los falsos positivos.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}